{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee0566b",
   "metadata": {},
   "source": [
    "### Content\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Libraries Used](#Importing-Libraries)\n",
    "- [Data Used](#Load-Data)\n",
    "- [EDA](#EDA)\n",
    "- [Prediction for Kaggle Submission](#Make-Prediction-Using-\"Test.csv\"-for-Kaggle-Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b6efe",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "<br>\n",
    "New buyers of residential properties usually are unfamiliar if a residential is over-priced or under-priced. You are tasked to create a model that will help buyers to evaluate the reasonable selling price for residential properties so that they are not over-paying for them and know when a property is a good deal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e0696",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245f4498",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdbeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7881fb5",
   "metadata": {},
   "source": [
    "### Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24907a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_count_subplot(x, feature_list, data, row, col, figure_size=(20, 15)):\n",
    "    # This function plots boxplot and count bar graph for each feature as as subplots\n",
    "    # Declaring and initialising variables\n",
    "    fig, ax = plt.subplots(figsize=figure_size, nrows=2, ncols = 3)\n",
    "    i = 0\n",
    "    \n",
    "    # Loop through feature_list to create subplot for each feature\n",
    "    for feature in feature_list:\n",
    "        sns.boxplot(x=x, y=feature, data=data, ax=ax[0,i], order=data[feature].value_counts().index)\n",
    "        sns.barplot(x=data[feature].value_counts(),y=data[feature].value_counts().index, ax=ax[1, i])\n",
    "        i+=1\n",
    "\n",
    "#----------------------------------------------------------------------------------------------        \n",
    "        \n",
    "def corr_plots(data, heatmap_size=(8, 8), heatmap_title_fontsize = 16, pair_title_fontsize = 16):\n",
    "    # Heatmap\n",
    "    plt.figure(figsize=heatmap_size)\n",
    "    pearson_corr = data.corr()\n",
    "    mask = np.zeros_like(pearson_corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(pearson_corr, annot=True, mask=mask, vmax = 1, vmin = -1)\n",
    "    plt.title('Correlation Heatmap', fontweight = 'bold', fontsize=heatmap_title_fontsize)\n",
    "    \n",
    "    # Plot Pairplot\n",
    "    pair = sns.pairplot(data)\n",
    "    pair.fig.suptitle('Pairplot Between Features', fontweight = 'bold', fontsize=pair_title_fontsize)\n",
    "    pair.fig.subplots_adjust(top=0.9)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "    \n",
    "def scatter_plot_3_features(data, x, y, features_list, rows, cols, \n",
    "                        figsize=(12,12), t_fontsize=10, t_dist_top = 0.9, marker_size=10):\n",
    "    '''\n",
    "    data: DataFrame of the data\n",
    "    x: String. Numeric common feature to be set as x axis of all subplots\n",
    "    y: String. Numeric common feature to be set as x axis of all subplots\n",
    "    Features: List of strings to be set as hue in scatterplot\n",
    "    rows: No of rows\n",
    "    cols: No of cols\n",
    "    figsize: tuple (Width, Height)\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=figsize, nrows=rows, ncols=cols)\n",
    "    for i in range(len(features_list)):\n",
    "        if rows > 1 and cols > 1:\n",
    "            sns.scatterplot(x=x, y=y, data=data, hue=features_list[i], ax=ax[int(i/cols),i%cols], s=marker_size)\n",
    "            ax[int(i/cols),i%cols].set_title(f\"{y} vs {x} By {features_list[i]}\")\n",
    "        else:\n",
    "            sns.scatterplot(x=x, y=y, data=data, hue=features_list[i], ax=ax[i], s=marker_size)\n",
    "            ax[i].set_title(f\"{y} vs {x} By {features_list[i]}\")\n",
    "    plt.suptitle(f\"{y} vs {x} By Various Features\", fontweight='bold', fontsize=t_fontsize)\n",
    "    fig.subplots_adjust(top=t_dist_top)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "    \n",
    "def scatter_plot_by_labels(data, x, y, feature, rows, cols,\n",
    "                          figsize=(12,12), t_fontsize=10, t_dist_top = 0.9, marker_size=10, ci=95):\n",
    "    fig, ax = plt.subplots(figsize = figsize, nrows = rows, ncols = cols, sharex=True, sharey=True, squeeze=False)\n",
    "    for i in range(data[feature].nunique()):\n",
    "        sns.regplot(x=x, y=y, data=data[data[feature]==data[feature].unique()[i]],\n",
    "                    ax=ax[int(i/cols),i%cols], ci=ci, line_kws={'color':'red'},\n",
    "                    scatter_kws={'s':marker_size})\n",
    "        ax[int(i/cols),i%cols].set_title(data[feature].unique()[i])\n",
    "    fig.suptitle(f'{y} vs {x} by {feature}', fontsize=t_fontsize, fontweight=\"bold\")\n",
    "    fig.subplots_adjust(top=t_dist_top)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def prePost_logtransform(data, x, y, feature, label, figsize=(12,12), t_fontsize=10,\n",
    "                         t_dist_top = 0.9):\n",
    "    fig, ax = plt.subplots(figsize=figsize, nrows=1, ncols=2, sharey=True)\n",
    "    # Comparison of scatter plot before and after transformation of x \n",
    "    # Plot for Sale Price vs Lot Area - Before Transformation for feature = label\n",
    "    sns.regplot(x=x, y=y, data=data[data[feature]==label], ax=ax[0])\n",
    "    ax[0].set_title('Sale Price vs Lot Area - Before Transformation')\n",
    "    ax[0].set_xticks(ax[0].get_xticks())\n",
    "    ax[0].set_xticklabels(ax[0].get_xticks(), rotation=90)\n",
    "\n",
    "    # Plot for Sale Price vs Lot Area - After Transformation for Neighborhood = Edwards\n",
    "    sns.regplot(x=np.log(data[data[feature]==label][x]), y=data[data[feature]==label][y], ax=ax[1])\n",
    "    ax[1].set_title('Sale Price vs Lot Area - After Transformation')\n",
    "\n",
    "    # Set Main Title\n",
    "    fig.suptitle(f'Effect of Transformation on Lot Area for {feature}: {label}', fontsize = t_fontsize, fontweight='bold')\n",
    "    fig.subplots_adjust(top=t_dist_top)\n",
    "    \n",
    "    # Correlation Values\n",
    "    temp = data[data[feature]==label].copy()\n",
    "    new_x = x + '_log'\n",
    "    temp[new_x] = np.log(temp[x])\n",
    "    pearson_corr = temp[[x, new_x, y]].corr()\n",
    "    print(pearson_corr)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def imputing_lot_frontage(data):\n",
    "    temp = data[data['Lot Area'] < 30000][['Lot Area', 'Lot Frontage']]\n",
    "    temp.dropna(inplace=True)\n",
    "\n",
    "    # Train Test Split Data Set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(temp[['Lot Area']], temp['Lot Frontage'], train_size = 0.8, random_state=60)\n",
    "\n",
    "    # Instantiate OLS Model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "\n",
    "    # Get index for missing Lot Frontage data for Lot Area < 30000\n",
    "    missing_index = data[(data['Lot Area'] < 30000) & (data['Lot Frontage'].isnull())]['Lot Frontage'].index\n",
    "\n",
    "    # Imputing data and save into Lot Frontage_Imputed\n",
    "    data['Lot Frontage_Imputed'] = data['Lot Frontage']\n",
    "    for i in missing_index:\n",
    "        data.loc[i, 'Lot Frontage_Imputed'] = lr.predict([[data.loc[i, 'Lot Area']]])\n",
    "        \n",
    "    return data \n",
    "    \n",
    "#----------------------------------------------------------------------------------------------\n",
    "    \n",
    "def clean(data):\n",
    "    data=data.copy()\n",
    "    # Converting MS SubClass, Overall Qual, Overall Cond to string as it is categorical data\n",
    "    data['MS SubClass'] = data['MS SubClass'].astype('str')\n",
    "    data['Overall Qual'] = data['Overall Qual'].astype('str')\n",
    "    data['Overall Cond'] = data['Overall Qual'].astype('str')\n",
    "    \n",
    "    # Replace all 'NaN' from object columns\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == 'O':\n",
    "            if column in ['Mas Vnr Type', 'Misc Feature']:\n",
    "                data[column].replace(np.nan, 'None', inplace=True)\n",
    "            else:\n",
    "                data[column].replace(np.nan, 'n.a', inplace=True)\n",
    "    \n",
    "    # New Column for 'Garage Yr Blt and Impute missing 'Garage Yr Blt' rows with 'Year Built' data\n",
    "    data['Garage Yr Blt_Imputed'] = data['Garage Yr Blt'].fillna(value=data['Year Built'])\n",
    "    \n",
    "    # Imputing Lot Frontage based on Linear Regression Model using Lot Area\n",
    "    data = imputing_lot_frontage(data)\n",
    "               \n",
    "    # Set 0 for rows with house style as 1story but 2nd level SF is not 0\n",
    "    data.loc[(data['House Style'] == '1Story') & (data['2nd Flr SF'] > 0), '2nd Flr SF'] = 0\n",
    " \n",
    "    return data\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def prep(data):\n",
    "    data=data.copy()\n",
    "    # Engineering new numeric features\n",
    "    data['Total SF'] = data['Total Bsmt SF'] + data['1st Flr SF'] + data['2nd Flr SF']\n",
    "    data['Total SF**2'] = (data['Total Bsmt SF'] + data['1st Flr SF'] + data['2nd Flr SF'])**2\n",
    "    data['No Of Bath'] = data['Bsmt Full Bath'] + (data['Bsmt Half Bath']/2) + data['Full Bath'] + (data['Half Bath']/2)\n",
    "    data['Total Porch SF'] = data['Open Porch SF'] + data['Enclosed Porch'] + data['3Ssn Porch'] + data['Screen Porch']\n",
    "    data['Amenities SF'] = data['Pool Area'] + data['Wood Deck SF'] + data['Garage Area']\n",
    "    data['Age_Sold'] = data['Yr Sold'] - data['Year Built']\n",
    "    data['Remod/Add Age_Sold'] = data['Yr Sold'] - data['Year Remod/Add']\n",
    "    data['Gr Liv Area**2'] = data['Gr Liv Area']**2\n",
    "\n",
    "    # Dropping Lot Frontage and Garage Yr Blt\n",
    "    data.drop(columns = ['Lot Frontage', 'Garage Yr Blt'], inplace=True)\n",
    "                                                         \n",
    "    return data\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def residual_plot(model, predictors, target, fig_title):\n",
    "    plt.scatter(model.predict(predictors), target - model.predict(predictors))\n",
    "    plt.axhline(y = 0, color='red')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residual (Target - Predicted)')\n",
    "    plt.title(fig_title)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "def output_result(model_type, features, Train_R2, Train_CV_R2, Test_R2, Train_RMSE, Train_CV_RMSE, Test_RMSE):\n",
    "    results = pd.DataFrame([[model_type, str(features), Train_R2, Train_CV_R2, Test_R2, Train_RMSE, Train_CV_RMSE, Test_RMSE]])\n",
    "    results.to_csv(r'..\\datasets\\results.csv', index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6cef7",
   "metadata": {},
   "source": [
    "### Make Prediction Using \"Test.csv\" for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "ca2f1c6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-798-fce4b22165a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prep data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_prep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_features_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_prep' is not defined"
     ]
    }
   ],
   "source": [
    "# Prep data\n",
    "test_X = clean_prep(test)\n",
    "test_X = test_X[model_features_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a41174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for Null values\n",
    "temp = test_X.isnull().sum()\n",
    "for i in range(len(temp)):\n",
    "    print(temp.index[i], ': ',  temp[i], ', Percentage of All Rows', \": \", temp[i]/test_X.shape[0], ' Type: ', test_X.dtypes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing row with mean\n",
    "if 'Mas Vnr Area' in test_X.columns:\n",
    "    test_X['Mas Vnr Area'] = test_X['Mas Vnr Area'].fillna(X_train['Mas Vnr Area'].mean())\n",
    "\n",
    "# One Hot Encoding\n",
    "test_X_OHE = pd.get_dummies(data=test_X, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d489fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features in trained model but not in test data (after One Hot Encoding)\n",
    "missing_feature_in_test = []\n",
    "for feature in X_train.columns:\n",
    "    if feature not in test_X_OHE.columns:\n",
    "        missing_feature_in_test.append(feature)\n",
    "        \n",
    "# Features in trained model but not in test data (after One Hot Encoding)\n",
    "missing_feature_in_train = []\n",
    "for feature in test_X_OHE.columns:\n",
    "    if feature not in X_train.columns:\n",
    "        missing_feature_in_train.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6635451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features which are in training data model but not in test data and assign 0 to them\n",
    "for feature in missing_feature_in_test:\n",
    "       test_X_OHE[feature] = 0\n",
    "\n",
    "# Drop features in test data which is not in trained model\n",
    "test_X_OHE.drop(columns=missing_feature_in_train, inplace=True)\n",
    "\n",
    "# Scale using StandardScaler\n",
    "test_X_OHE_scaled = ss.transform(test_X_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data using ridge regression\n",
    "y_test_predict = np.log(ridge_model.predict(test_X_OHE_scaled))\n",
    "\n",
    "# Put prediction results into dataframe with Id column\n",
    "test_result = pd.DataFrame(y_test_predict, columns = ['SalePrice'])\n",
    "test_result['Id'] = test['Id']\n",
    "\n",
    "# Write to csv file\n",
    "test_result.to_csv('..\\datasets\\kaggle_submission_ridge.csv', index = False, columns=['Id', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ce26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data using lasso regression\n",
    "y_test_predict = np.log(lasso_model.predict(test_X_OHE_scaled))\n",
    "\n",
    "# Put prediction results into dataframe with Id column\n",
    "test_result = pd.DataFrame(y_test_predict, columns = ['SalePrice'])\n",
    "test_result['Id'] = test['Id']\n",
    "\n",
    "# Write to csv file\n",
    "test_result.to_csv('..\\datasets\\kaggle_submission_lasso.csv', index = False, columns=['Id', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91772f3b",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eefb3d",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b4a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b671fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
